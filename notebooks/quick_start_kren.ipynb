# Quick Start Demo for Kren v1

from transformers import AutoTokenizer, AutoModelForCausalLM

# Load model and tokenizer from Hugging Face Hub
tokenizer = AutoTokenizer.from_pretrained("MWirelabs/kren-v1")
model = AutoModelForCausalLM.from_pretrained("MWirelabs/kren-v1")

# Example input
inputs = tokenizer("Ka Khasi ka", return_tensors="pt")

# Generate output
outputs = model.generate(inputs.input_ids, max_length=50)

# Decode and print
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
